{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from model_unet import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                  PART-1:Pre-processing tasks\\n\\n    1.Taking audio converting it into numpy matrix using librosa.load\\n    2.Staking all the input data same way using np.vstack\\n    3.Then to create noisy data,blend both numpy_vstack into 50 samples.\\n    4.Convert them into spectrgrams using librosa.stft \\n    \\n    '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                   \n",
    "    '''                  PART-1:Pre-processing tasks\n",
    "    \n",
    "        1.Taking audio converting it into numpy matrix using librosa.load\n",
    "        2.Staking all the input data same way using np.vstack\n",
    "        3.Then to create noisy data,blend both numpy_vstack into 50 samples.\n",
    "        4.Convert them into spectrgrams using librosa.stft \n",
    "        \n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n",
    "    \"\"\"This function take an audio and split into several frame\n",
    "       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n",
    "\n",
    "    sequence_sample_length = sound_data.shape[0]\n",
    "\n",
    "    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n",
    "    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n",
    "    sound_data_array = np.vstack(sound_data_list)\n",
    "\n",
    "    return sound_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n",
    "    \"\"\"This function take audio files of a directory and merge them\n",
    "    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n",
    "\n",
    "    list_sound_array = []\n",
    "\n",
    "    for file in list_audio_files:\n",
    "        # open the audio file\n",
    "        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n",
    "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        if (total_duration >= min_duration):\n",
    "            list_sound_array.append(audio_to_audio_frame_stack(\n",
    "                y, frame_length, hop_length_frame))\n",
    "        else:\n",
    "            print(\n",
    "                f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n",
    "\n",
    "    return np.vstack(list_sound_array)\n",
    "\n",
    "\n",
    "def blend_noise_randomly(voice, noise, nb_samples, frame_length):\n",
    "    \"\"\"This function takes as input numpy arrays representing frames\n",
    "    of voice sounds, noise sounds and the number of frames to be created\n",
    "    and return numpy arrays with voice randomly blend with noise\"\"\"\n",
    "\n",
    "    prod_voice = np.zeros((nb_samples, frame_length))\n",
    "    prod_noise = np.zeros((nb_samples, frame_length))\n",
    "    prod_noisy_voice = np.zeros((nb_samples, frame_length))\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        id_voice = np.random.randint(0, voice.shape[0])\n",
    "        id_noise = np.random.randint(0, noise.shape[0])\n",
    "        level_noise = np.random.uniform(0.2, 0.8)\n",
    "        prod_voice[i, :] = voice[id_voice, :]\n",
    "        prod_noise[i, :] = level_noise * noise[id_noise, :]\n",
    "        prod_noisy_voice[i, :] = prod_voice[i, :] + prod_noise[i, :]\n",
    "\n",
    "    return prod_voice, prod_noise, prod_noisy_voice\n",
    "\n",
    "\n",
    "def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n",
    "    \"\"\"This function takes an audio and convert into spectrogram,\n",
    "       it returns the magnitude in dB and the phase\"\"\"\n",
    "\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
    "        stftaudio_magnitude, ref=np.max)\n",
    "\n",
    "    return stftaudio_magnitude_db, stftaudio_phase\n",
    "\n",
    "\n",
    "def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
    "    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n",
    "    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n",
    "    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n",
    "\n",
    "    nb_audio = numpy_audio.shape[0]\n",
    "\n",
    "    m_mag_db = np.zeros((nb_audio, dim_square_spec, 128))\n",
    "    m_phase = np.zeros((nb_audio, dim_square_spec, 128), dtype=complex)\n",
    "\n",
    "    for i in range(nb_audio):\n",
    "        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(\n",
    "            n_fft, hop_length_fft, numpy_audio[i])\n",
    "\n",
    "    return m_mag_db, m_phase\n",
    "\n",
    "\n",
    "def magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n",
    "    \"\"\"This functions reverts a spectrogram to an audio\"\"\"\n",
    "\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # taking magnitude and phase of audio\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n",
    "\n",
    "    return audio_reconstruct\n",
    "\n",
    "def matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n",
    "    \"\"\"This functions reverts the matrix spectrograms to numpy audio\"\"\"\n",
    "\n",
    "    list_audio = []\n",
    "\n",
    "    nb_spec = m_mag_db.shape[0]\n",
    "\n",
    "    for i in range(nb_spec):\n",
    "\n",
    "        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n",
    "        list_audio.append(audio_reconstruct)\n",
    "\n",
    "    return np.vstack(list_audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_in(matrix_spec):\n",
    "    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec + 46)/50\n",
    "    return matrix_spec\n",
    "\n",
    "def scaled_ou(matrix_spec):\n",
    "    \"global scaling apply to noise models spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec -6 )/82\n",
    "    return matrix_spec\n",
    "\n",
    "def inv_scaled_in(matrix_spec):\n",
    "    \"inverse global scaling apply to noisy voices spectrograms\"\n",
    "    matrix_spec = matrix_spec * 50 - 46\n",
    "    return matrix_spec\n",
    "\n",
    "def inv_scaled_ou(matrix_spec):\n",
    "    \"inverse global scaling apply to noise models spectrograms\"\n",
    "    matrix_spec = matrix_spec * 82 + 6\n",
    "    return matrix_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(noise_dir, voice_dir, path_save_time_serie, path_save_sound, path_save_spectrogram, sample_rate,\n",
    "min_duration, frame_length, hop_length_frame, hop_length_frame_noise, nb_samples, n_fft, hop_length_fft):\n",
    "    \"\"\"This function will randomly blend some clean voices from voice_dir with some noises from noise_dir\n",
    "    and save the spectrograms of noisy voice, noise and clean voices to disk as well as complex phase,\n",
    "    time series and sounds. This aims at preparing datasets for denoising training. It takes as inputs\n",
    "    parameters defined in args module\"\"\"\n",
    "\n",
    "    list_noise_files = os.listdir(noise_dir)\n",
    "    list_voice_files = os.listdir(voice_dir)\n",
    "\n",
    "    def remove_ds_store(lst):\n",
    "        \"\"\"remove mac specific file if present\"\"\"\n",
    "        if '.DS_Store' in lst:\n",
    "            lst.remove('.DS_Store')\n",
    "\n",
    "        return lst\n",
    "\n",
    "    list_noise_files = remove_ds_store(list_noise_files)\n",
    "    list_voice_files = remove_ds_store(list_voice_files)\n",
    "\n",
    "    nb_voice_files = len(list_voice_files)\n",
    "    nb_noise_files = len(list_noise_files)\n",
    "\n",
    "\n",
    "    # Extracting noise and voice from folder and convert to numpy\n",
    "    noise = audio_files_to_numpy(noise_dir, list_noise_files, sample_rate,\n",
    "                                     frame_length, hop_length_frame_noise, min_duration)\n",
    "\n",
    "    voice = audio_files_to_numpy(voice_dir, list_voice_files,\n",
    "                                     sample_rate, frame_length, hop_length_frame, min_duration)\n",
    "\n",
    "    # Blend some clean voices with random selected noises (and a random level of noise)\n",
    "    prod_voice, prod_noise, prod_noisy_voice = blend_noise_randomly(\n",
    "            voice, noise, nb_samples, frame_length)\n",
    "\n",
    "    # To save the long audio generated to disk to QC:\n",
    "    noisy_voice_long = prod_noisy_voice.reshape(1, nb_samples * frame_length)\n",
    "    soundfile.write(path_save_sound + '/noisy_voice_long.wav', noisy_voice_long[0, :], sample_rate)\n",
    "    voice_long = prod_voice.reshape(1, nb_samples * frame_length)\n",
    "    soundfile.write(path_save_sound + '/voice_long.wav', voice_long[0, :], sample_rate)\n",
    "    noise_long = prod_noise.reshape(1, nb_samples * frame_length)\n",
    "    soundfile.write(path_save_sound + '/noise_long.wav', noise_long[0, :], sample_rate)\n",
    "\n",
    "    # Squared spectrogram dimensions\n",
    "    dim_square_spec = int(n_fft / 2) + 1\n",
    "\n",
    "    # Create Amplitude and phase of the sounds\n",
    "    m_amp_db_voice,  m_pha_voice = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_voice, dim_square_spec, n_fft, hop_length_fft)\n",
    "    m_amp_db_noise,  m_pha_noise = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_noise, dim_square_spec, n_fft, hop_length_fft)\n",
    "    m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n",
    "            prod_noisy_voice, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "    # Save to disk for Training / QC\n",
    "    np.save(path_save_time_serie + '/voice_timeserie', prod_voice)\n",
    "    np.save(path_save_time_serie + '/noise_timeserie', prod_noise)\n",
    "    np.save(path_save_time_serie + '/noisy_voice_timeserie', prod_noisy_voice)\n",
    "\n",
    "\n",
    "    np.save(path_save_spectrogram + '/voice_amp_db', m_amp_db_voice)\n",
    "    np.save(path_save_spectrogram + '/noise_amp_db', m_amp_db_noise)\n",
    "    np.save(path_save_spectrogram + '/noisy_voice_amp_db', m_amp_db_noisy_voice)\n",
    "\n",
    "    np.save(path_save_spectrogram + '/voice_pha_db', m_pha_voice)\n",
    "    np.save(path_save_spectrogram + '/noise_pha_db', m_pha_noise)\n",
    "    np.save(path_save_spectrogram + '/noisy_voice_pha_db', m_pha_noisy_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=8000\n",
    "min_duration=1.0\n",
    "frame_length=8064\n",
    "hop_length_frame=8064\n",
    "hop_length_frame_noise=5000\n",
    "nb_samples=50\n",
    "n_fft=255\n",
    "hop_length_fft=63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data('noise','clean_voice','time_serie','sound','spectrogram', sample_rate,min_duration,frame_length,hop_length_frame,hop_length_frame_noise,nb_samples,n_fft,hop_length_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                       '''U-NET Model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training_the_model(if you have enough storage you can but I am using an pre-trained model )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(path_save_spectrogram, weights_path, name_model, epochs, batch_size):\n",
    "    \"\"\" This function will read noisy voice and clean voice spectrograms created by data_creation mode,\n",
    "    and train a Unet model on this dataset for epochs and batch_size specified. It saves best models to disk regularly\n",
    "    If training_from_scratch is set to True it will train from scratch, if set to False, it will train\n",
    "    from weights (name_model) provided in weights_path\n",
    "    \"\"\"\n",
    "    #load noisy voice & clean voice spectrograms created by data_creation mode\n",
    "    X_in = np.load(path_save_spectrogram +'/noisy_voice_amp_db'+\".npy\")\n",
    "    X_ou = np.load(path_save_spectrogram +'/voice_amp_db'+\".npy\")\n",
    "    #Model of noise to predict\n",
    "    X_ou = X_in - X_ou\n",
    "\n",
    "    #Check distribution\n",
    "    print(stats.describe(X_in.reshape(-1,1)))\n",
    "    print(stats.describe(X_ou.reshape(-1,1)))\n",
    "\n",
    "    #to scale between -1 and 1\n",
    "    X_in = scaled_in(X_in)\n",
    "    X_ou = scaled_ou(X_ou)\n",
    "\n",
    "    #Check shape of spectrograms\n",
    "    print(X_in.shape)\n",
    "    print(X_ou.shape)\n",
    "    #Check new distribution\n",
    "    print(stats.describe(X_in.reshape(-1,1)))\n",
    "    print(stats.describe(X_ou.reshape(-1,1)))\n",
    "\n",
    "\n",
    "    #Reshape for training\n",
    "    X_in = X_in[:,:,:]\n",
    "    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
    "    X_ou = X_ou[:,:,:]\n",
    "    X_ou = X_ou.reshape(X_ou.shape[0],X_ou.shape[1],X_ou.shape[2],1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n",
    "\n",
    "#     #If training from scratch\n",
    "#     if training_from_scratch:\n",
    "\n",
    "#         generator_nn=unet()\n",
    "#     #If training from pre-trained weights\n",
    "#     else:\n",
    "\n",
    "    generator_nn=unet(pretrained_weights = weights_path+name_model+'.h5')\n",
    "\n",
    "\n",
    "    #Save best models to disk during training\n",
    "    checkpoint = ModelCheckpoint(weights_path+'/model_best.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "\n",
    "    generator_nn.summary()\n",
    "    #Training\n",
    "    history = generator_nn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[checkpoint], verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    #Plot training and validation loss (log scale)\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, label='Training loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation loss')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model='/model_unet'\n",
    "epochs=2\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=819200, minmax=(array([-80.]), array([0.])), mean=array([-45.410623]), variance=array([184.93696546]), skewness=array([0.18438214]), kurtosis=array([0.58380917]))\n",
      "DescribeResult(nobs=819200, minmax=(array([-53.81084212]), array([79.87740082])), mean=array([7.24345461]), variance=array([225.63653545]), skewness=array([0.29061321]), kurtosis=array([-0.48003656]))\n",
      "(50, 128, 128)\n",
      "(50, 128, 128)\n",
      "DescribeResult(nobs=819200, minmax=(array([-0.68]), array([0.92])), mean=array([0.01178754]), variance=array([0.07397479]), skewness=array([0.18438214]), kurtosis=array([0.58380917]))\n",
      "DescribeResult(nobs=819200, minmax=(array([-0.72940051]), array([0.90094391])), mean=array([0.01516408]), variance=array([0.03355689]), skewness=array([0.29061321]), kurtosis=array([-0.48003656]))\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 16) 160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 16) 2320        leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 16)   0           leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 32)   4640        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 64, 64, 32)   9248        leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 32)   0           leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 64)   18496       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 64)   36928       leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 64)   0           leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 128)  73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 128)  147584      leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 128)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 256)    590080      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 16, 16, 256)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 128)  131200      up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 128)  147584      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 128)  0           leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 64)   32832       up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 128)  0           leaky_re_lu_51[0][0]             \n",
      "                                                                 leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 64)   36928       leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 64, 64, 64)   0           leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 32)   8224        up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 64, 64, 64)   0           leaky_re_lu_49[0][0]             \n",
      "                                                                 leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 32)   9248        leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 128, 128, 32) 0           leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 128, 128, 16) 2064        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128, 128, 32) 0           leaky_re_lu_47[0][0]             \n",
      "                                                                 leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 128, 128, 16) 2320        leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 128, 128, 2)  290         leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 128, 128, 2)  0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 128, 1)  3           leaky_re_lu_68[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,941,093\n",
      "Trainable params: 1,941,093\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.0107 - mae: 0.1154\n",
      "Epoch 00001: val_loss improved from inf to 0.01013, saving model to weights/model_best.h5\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.0107 - mae: 0.1154 - val_loss: 0.0101 - val_mae: 0.1114\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084 - mae: 0.1001\n",
      "Epoch 00002: val_loss did not improve from 0.01013\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.0084 - mae: 0.1001 - val_loss: 0.0155 - val_mae: 0.1300\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training('spectrogram', 'weights', name_model,epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction, audio_input_prediction,\n",
    "audio_output_prediction, sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft):\n",
    "    \"\"\" This function takes as input pretrained weights, noisy voice sound to denoise, predict\n",
    "    the denoise sound and save it to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(weights_path+'/'+name_model+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_path+'/'+name_model+'.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # Extracting noise and voice from folder and convert to numpy\n",
    "    audio_to_stack=[]\n",
    "    y, sr = librosa.load(os.path.join('dir_for_prediction', 'noisy_voice_long.wav'), sr=sample_rate)\n",
    "    audio_to_stack.append(audio_to_audio_frame_stack(y, frame_length, hop_length_frame))\n",
    "    audio=np.vstack(audio_to_stack)\n",
    "\n",
    "    #Dimensions of squared spectrogram\n",
    "    dim_square_spec = int(n_fft / 2) + 1\n",
    "    print(dim_square_spec)\n",
    "\n",
    "    # Create Amplitude and phase of the sounds\n",
    "    m_amp_db_audio,  m_pha_audio = numpy_audio_to_matrix_spectrogram(\n",
    "        audio, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "    #global scaling to have distribution -1/1\n",
    "    X_in = scaled_in(m_amp_db_audio)\n",
    "    #Reshape for prediction\n",
    "    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
    "    #Prediction using loaded network\n",
    "    X_pred = loaded_model.predict(X_in)\n",
    "    #Rescale back the noise model\n",
    "    inv_sca_X_pred = inv_scaled_ou(X_pred)\n",
    "    #Remove noise model from noisy speech\n",
    "    X_denoise = m_amp_db_audio - inv_sca_X_pred[:,:,:,0]\n",
    "    #Reconstruct audio from denoised spectrogram and phase\n",
    "    print(X_denoise.shape)\n",
    "    print(m_pha_audio.shape)\n",
    "    print(frame_length)\n",
    "    print(hop_length_fft)\n",
    "    audio_denoise_recons = matrix_spectrogram_to_numpy_audio(X_denoise, m_pha_audio, frame_length, hop_length_fft)\n",
    "    #Number of frames\n",
    "    nb_samples = audio_denoise_recons.shape[0]\n",
    "    #Save all frames in one file\n",
    "    denoise_long = audio_denoise_recons.reshape(1, nb_samples * frame_length)*10\n",
    "    soundfile.write(dir_save_prediction + '/audio_output_prediction.wav', denoise_long[0, :], sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "128\n",
      "(50, 128, 128)\n",
      "(50, 128, 128)\n",
      "8064\n",
      "63\n"
     ]
    }
   ],
   "source": [
    " prediction('weights', name_model, 'dir_for_prediction', 'saved_output', 'noisy_voice_long.wav',\n",
    "        'audio_output_prediction', sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
